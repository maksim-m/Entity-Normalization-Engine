{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from classification.ClassificationDataset import ClassificationDataset\n",
    "from classification.model.SentenceTransformerAndClassifier import SentenceTransformerAndClassifier\n",
    "from utils import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "BATCH_SIZE = 512\n",
    "SHUFFLE = True\n",
    "SEED = 42\n",
    "VALIDATION_SPLIT = 0.05\n",
    "EPOCHS = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device: \", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def prepare_dataloaders(dataset: ClassificationDataset, validation_split: float):\n",
    "    dataset_size = len(dataset)\n",
    "    print(\"Dataset size: \", dataset_size)\n",
    "    print(dataset.index2label)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if SHUFFLE:\n",
    "        np.random.seed(SEED)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    print(\"Train size: {}, Val size: {}\".format(len(train_indices), len(val_indices)))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                              sampler=train_sampler)\n",
    "    validation_loader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                   sampler=valid_sampler)\n",
    "    return train_loader, validation_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def fit(model: SentenceTransformerAndClassifier, train_loader: DataLoader):\n",
    "    epoch_loss = 0\n",
    "    processed_samples = 0\n",
    "    correct_classified_samples = 0\n",
    "\n",
    "    model.train()\n",
    "    for step, data in enumerate(train_loader, 0):\n",
    "        input_ids = data[\"batch_encoding\"][\"input_ids\"].to(device)\n",
    "        attention_mask = data[\"batch_encoding\"][\"attention_mask\"].to(device)\n",
    "        input_ids = torch.squeeze(input_ids)\n",
    "        attention_mask = torch.squeeze(attention_mask)\n",
    "        targets = data[\"class_label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        epoch_loss += loss.item()\n",
    "        correct_classified_samples += torch.sum(predictions == targets).item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        processed_samples += len(data[\"class_label\"])\n",
    "\n",
    "    epoch_loss /= processed_samples\n",
    "    epoch_accuracy = correct_classified_samples / processed_samples\n",
    "    return {\n",
    "        \"loss\": epoch_loss,\n",
    "        \"acc\": epoch_accuracy\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def validate(model: SentenceTransformerAndClassifier, validation_loader: DataLoader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        processed_samples = 0\n",
    "        correct_classified_samples = 0\n",
    "\n",
    "        for step, data in enumerate(validation_loader, 0):\n",
    "            input_ids = data[\"batch_encoding\"][\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"batch_encoding\"][\"attention_mask\"].to(device)\n",
    "            input_ids = torch.squeeze(input_ids)\n",
    "            attention_mask = torch.squeeze(attention_mask)\n",
    "            targets = data[\"class_label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            correct_classified_samples += torch.sum(predictions == targets).item()\n",
    "\n",
    "            processed_samples += len(data[\"class_label\"])\n",
    "\n",
    "        val_loss /= processed_samples\n",
    "        val_accuracy = correct_classified_samples / processed_samples\n",
    "    return {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_accuracy\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "| linear_layer.weight |   393216   |\n",
      "|  linear_layer.bias  |    512     |\n",
      "|  classifier.weight  |    2560    |\n",
      "|   classifier.bias   |     5      |\n",
      "+---------------------+------------+\n",
      "Total trainable parameters: 396293\n"
     ]
    },
    {
     "data": {
      "text/plain": "396293"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "model = SentenceTransformerAndClassifier(base_model, n_classes=5)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model.to(device)\n",
    "model.describe_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  24995\n",
      "{0: 'address', 1: 'company_name', 2: 'location', 3: 'physical_good', 4: 'serial_number'}\n",
      "Train size: 23746, Val size: 1249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = ClassificationDataset(Path.joinpath(PROJECT_ROOT, \"data/processed\"), tokenizer, MAX_LEN)\n",
    "train_loader, validation_loader = prepare_dataloaders(dataset, VALIDATION_SPLIT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n",
      "Loss: 0.0009428589104110064, Acc: 0.9145961425082119\n",
      "Val Loss: 0.00017952515458087142, Val Acc: 0.9847878302642114\n",
      "Epoch 2/3\n",
      "----------\n",
      "Loss: 0.00014538020519938975, Acc: 0.9801229680788344\n",
      "Val Loss: 9.983928323841935e-05, Val Acc: 0.9879903923138511\n",
      "Epoch 3/3\n",
      "----------\n",
      "Loss: 0.00011213524644375651, Acc: 0.984923776636065\n",
      "Val Loss: 9.242845050471605e-05, Val Acc: 0.9895916733386709\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, EPOCHS))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    logs = fit(model, train_loader)\n",
    "\n",
    "    print(\"Loss: {}, Acc: {}\".format(\n",
    "        logs[\"loss\"],\n",
    "        logs[\"acc\"]\n",
    "    ))\n",
    "\n",
    "    val_logs = validate(model, validation_loader)\n",
    "    print(\"Val Loss: {}, Val Acc: {}\".format(\n",
    "        val_logs[\"val_loss\"],\n",
    "        val_logs[\"val_acc\"],\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), Path.joinpath(PROJECT_ROOT, \"save_dict_model.pt\").absolute())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}